{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Setting the face image data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xj9zxvd0zitJ"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"Dataset/Lwando/*.jpg\" # The image directory path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PbToJUHx0hew"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the image generator class with brightness range and horizontal flip as options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LauXWtn5j5M"
   },
   "outputs": [],
   "source": [
    "GENERATOR = ImageDataGenerator(brightness_range=[1,1.5], horizontal_flip=True) # Instanciating the Image Generator class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriving the face extraction xml file from open-cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Pl9dgSBCfY4"
   },
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping the image to the necessary facial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZgJqVU6FC6Hm"
   },
   "outputs": [],
   "source": [
    "def Get_Face(IMAGE):\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "                    IMAGE,\n",
    "                    scaleFactor=1.3,\n",
    "                    minNeighbors=3,\n",
    "                    minSize=(30, 30)\n",
    "                ) # faces contains an array of face coordinates that are obtained from the image.  \n",
    "        \n",
    "        if(len(faces) == 0 ): return None # This line checks if there are values in faces, if the length of the array is 0 then no face was detected\n",
    "        for (x, y, w, h) in faces:\n",
    "              cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2) #This line draws a bounding box on the detected face.\n",
    "              cropped_img = img[y:y + h, x:x + w] # This line crops the image to the facial coordinates obtained from the faces variable.\n",
    "        return cropped_img #returning the cropped image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cell below opens images within a directory, crops the images to the facial features and inserts those cropped images into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Md5N6jdT0HKx"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 500\n",
    "IMAGES = []\n",
    "\n",
    "for image in glob.glob(IMAGE_PATH):\n",
    "\n",
    "        img = cv2.imread(image) #Raading the Image from the directory\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n",
    "        img = Get_Face(img) #croppng the image to the required facial features\n",
    "        try:\n",
    "            if(img.any()): #Seeing if a face was detected in the image otherwise the image will not be added to the array\n",
    "                img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "                IMAGES.append(img)\n",
    "              \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "IMAGES = np.array(IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pG0VrpV4NQ2X"
   },
   "outputs": [],
   "source": [
    "plt.imshow(IMAGES[4]) #Displaying the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXZGnY2u1QL7"
   },
   "outputs": [],
   "source": [
    "aug_itr = GENERATOR.flow(IMAGES) # creating an iterator\n",
    "aug_img = [next(aug_itr)[0].astype(np.uint8) for i in range(100)] #Genrating new images\n",
    "for x,i in enumerate(aug_img):\n",
    "        im = Image.fromarray(i)\n",
    "        im.save(\"/Dataset/Lwando/_IMG_{}\".format(x),\"jpeg\") #saving the new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOGlknC11TIS"
   },
   "outputs": [],
   "source": [
    "plt.imshow(aug_img[72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7WXK7TkBWHr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IoT Proj Image augmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
